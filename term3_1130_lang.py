#!/usr/bin/env python3
"""
SketchToSpec: ì£¼ì œ + ê¸°ëŠ¥ ì²´í¬ë°•ìŠ¤ + ì†ê·¸ë¦¼ â†’ ìš”êµ¬ì‚¬í•­ & ASCII ë‹¤ì´ì–´ê·¸ë¨
- Streamlit UI
- ë¡œì»¬ GPU LLM ì‚¬ìš© (ì˜ˆ: Qwen/Qwen2-7B-Instruct)
"""

import os
import json
from dataclasses import dataclass, asdict
from typing import List, Dict, Any, Tuple, TypedDict, Optional

import streamlit as st

try:
    import cv2  # type: ignore
    import numpy as np  # type: ignore
except Exception:
    cv2 = None
    np = None

import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from langgraph.graph import StateGraph, END

# ------------------------------------------------------------------------------------
# ëª¨ë¸ ì„¤ì •
# ------------------------------------------------------------------------------------
MODEL_NAME = os.getenv("SKETCHTOSPEC_MODEL", "Qwen/Qwen2-7B-Instruct")
MAX_NEW_TOKENS = 1024
TEMPERATURE = 0.4
TOP_P = 0.9
MAX_AGENT_RETRIES = 2


# ------------------------------------------------------------------------------------
# Dataclass ì •ì˜
# ------------------------------------------------------------------------------------
@dataclass
class UIComponent:
    kind: str
    label: str
    bbox: List[int]  # [x1, y1, x2, y2]


class RequirementState(TypedDict, total=False):
    goal: str
    goal_topic: str
    sanitized_goal: str
    selected_features: List[Dict[str, str]]
    selected_ui: List[Dict[str, str]]
    detected_components: List[UIComponent]
    reasoning_notes: str
    info_requests: List[str]
    plan_outline: Dict[str, Any]
    plan_text: str
    action_prompt: str
    llm_output: str
    parsed_json: Dict[str, Any]
    result_payload: Dict[str, Any]
    errors: List[str]
    observations: List[str]
    actions_taken: List[str]
    tool_reports: List[Dict[str, Any]]
    gpu_metrics: List[Dict[str, Any]]
    retry_count: int
    should_retry: bool


# ------------------------------------------------------------------------------------
# ê³µí†µ "ê¸°ëŠ¥ ì²´í¬ë¦¬ìŠ¤íŠ¸" ì •ì˜ (ì£¼ì œì™€ ë¬´ê´€í•˜ê²Œ ìì£¼ ë“±ì¥í•˜ëŠ” ê¸°ëŠ¥)
# ------------------------------------------------------------------------------------
FEATURE_LIBRARY: List[Dict[str, str]] = [
    # ì¸ì¦ / ê³„ì •
    {"key": "signup", "category": "ì¸ì¦/ê³„ì •", "name": "íšŒì›ê°€ì…", "desc": "ì´ë©”ì¼/ë¹„ë°€ë²ˆí˜¸ë¡œ ê³„ì •ì„ ìƒì„±"},
    {"key": "login", "category": "ì¸ì¦/ê³„ì •", "name": "ë¡œê·¸ì¸", "desc": "ê¸°ì¡´ ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸"},
    {"key": "social_login", "category": "ì¸ì¦/ê³„ì •", "name": "ì†Œì…œ ë¡œê·¸ì¸", "desc": "ì¹´ì¹´ì˜¤/êµ¬ê¸€ ë“± ì™¸ë¶€ ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸"},
    {"key": "profile", "category": "ì¸ì¦/ê³„ì •", "name": "í”„ë¡œí•„ ê´€ë¦¬", "desc": "ë‚´ ì •ë³´ ë³´ê¸° ë° ìˆ˜ì •"},

    # ì½˜í…ì¸  / ëª©ë¡
    {"key": "list_view", "category": "ì½˜í…ì¸ ", "name": "ëª©ë¡ í™”ë©´", "desc": "ì—¬ëŸ¬ ê°œì˜ í•­ëª©ì„ ë¦¬ìŠ¤íŠ¸/ì¹´ë“œë¡œ ë³´ì—¬ì¤Œ"},
    {"key": "detail_view", "category": "ì½˜í…ì¸ ", "name": "ìƒì„¸ í™”ë©´", "desc": "ì„ íƒí•œ í•­ëª©ì˜ ìƒì„¸ ì •ë³´ í™”ë©´"},

    # ê²€ìƒ‰ / í•„í„°
    {"key": "search", "category": "ê²€ìƒ‰/í•„í„°", "name": "ê²€ìƒ‰", "desc": "í‚¤ì›Œë“œë¡œ í•­ëª© ê²€ìƒ‰"},
    {"key": "filter", "category": "ê²€ìƒ‰/í•„í„°", "name": "í•„í„°/ì •ë ¬", "desc": "ì¡°ê±´ì— ë”°ë¼ ê²°ê³¼ë¥¼ í•„í„°ë§/ì •ë ¬"},

    # ì»¤ë®¤ë‹ˆì¼€ì´ì…˜
    {"key": "chat", "category": "ì»¤ë®¤ë‹ˆì¼€ì´ì…˜", "name": "1:1 ì±„íŒ…", "desc": "ì‚¬ìš©ì ê°„ ëŒ€í™” ê¸°ëŠ¥"},
    {"key": "notification", "category": "ì»¤ë®¤ë‹ˆì¼€ì´ì…˜", "name": "ì•Œë¦¼", "desc": "ìƒˆ ë§¤ì¹­/ë©”ì‹œì§€ ë“± ì•Œë¦¼"},

    # ì¶”ì²œ
    {"key": "personalized_feed", "category": "ì¶”ì²œ", "name": "ê°œì¸í™” í”¼ë“œ", "desc": "ì‚¬ìš©ì ì„ í˜¸ë„ì— ê¸°ë°˜í•œ ì½˜í…ì¸  ì¶”ì²œ"},
    {"key": "trending", "category": "ì¶”ì²œ", "name": "íŠ¸ë Œë”© ì½˜í…ì¸ ", "desc": "í˜„ì¬ ì¸ê¸° ìˆëŠ” ì½˜í…ì¸  í‘œì‹œ"},

    # ì†Œì…œ
    {"key": "user_follow", "category": "ì†Œì…œ", "name": "ì‚¬ìš©ì íŒ”ë¡œìš°", "desc": "ë‹¤ë¥¸ ì‚¬ìš©ìë¥¼ íŒ”ë¡œìš°í•˜ê³  ì—…ë°ì´íŠ¸ë¥¼ ë°›ê¸°"},
    {"key": "comments", "category": "ì†Œì…œ", "name": "ëŒ“ê¸€", "desc": "ì½˜í…ì¸ ì— ëŒ“ê¸€ì„ ë‹¬ê³  ì†Œí†µ"},

    # ìš´ì˜ / ê´€ë¦¬
    {"key": "analytics", "category": "ìš´ì˜/ê´€ë¦¬", "name": "ë¶„ì„ ëŒ€ì‹œë³´ë“œ", "desc": "ì‚¬ìš©ì í™œë™ ë° ì„±ê³¼ ë¶„ì„"},
    {"key": "content_moderation", "category": "ìš´ì˜/ê´€ë¦¬", "name": "ì½˜í…ì¸  ê´€ë¦¬", "desc": "ë¶€ì ì ˆí•œ ì½˜í…ì¸ ë¥¼ ê²€í†  ë° ê´€ë¦¬"},

    # ê¸°íƒ€
    {"key": "dark_mode", "category": "ê¸°íƒ€", "name": "ë‹¤í¬ ëª¨ë“œ", "desc": "ì–´ë‘ìš´ í…Œë§ˆë¡œ ì „í™˜"},
    {"key": "multi_language", "category": "ê¸°íƒ€", "name": "ë‹¤êµ­ì–´ ì§€ì›", "desc": "ì—¬ëŸ¬ ì–¸ì–´ë¡œ ì•± ì‚¬ìš© ê°€ëŠ¥"},
]


# ------------------------------------------------------------------------------------
# ëª¨ë¸ ë¡œë”©
# ------------------------------------------------------------------------------------
@st.cache_resource
def load_model():
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_NAME,
        torch_dtype=torch.float16,
        device_map="cuda",
    )
    return tokenizer, model


def apply_chat_template(tokenizer, messages):
    if hasattr(tokenizer, "apply_chat_template"):
        return tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True,
        )
    text = ""
    for m in messages:
        text += f"<|im_start|>{m['role']}\n{m['content']}\n<|im_end|>\n"
    return text + "<|im_start|>assistant\n"


def model_generate(prompt: str, tokenizer, model) -> str:
    messages = [{"role": "user", "content": prompt}]
    chat = apply_chat_template(tokenizer, messages)
    inputs = tokenizer(chat, return_tensors="pt").to(model.device)

    with torch.no_grad():
        output = model.generate(
            **inputs,
            max_new_tokens=MAX_NEW_TOKENS,
            temperature=TEMPERATURE,
            top_p=TOP_P,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id,
        )

    # ì…ë ¥ ê¸¸ì´ë§Œí¼ì€ í”„ë¡¬í”„íŠ¸ì´ë¯€ë¡œ ì˜ë¼ë‚¸ë‹¤
    input_len = inputs["input_ids"].shape[-1]
    generated_ids = output[0][input_len:]

    # ìƒˆë¡œ ìƒì„±ëœ ë¶€ë¶„ë§Œ ë””ì½”ë”©
    decoded = tokenizer.decode(generated_ids, skip_special_tokens=False)
    return decoded



def classify_goal(goal: str) -> str:
    """ì•± ì£¼ì œë¥¼ ê°„ë‹¨í•œ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•œë‹¤."""
    g = goal.lower()

    # ì†Œê°œíŒ… / ë§¤ì¹­
    if any(k in g for k in ["ì†Œê°œíŒ…", "ë°ì´íŠ¸", "ë§¤ì¹­", "ì—°ì• "]):
        return "ì†Œê°œíŒ…/ë§¤ì¹­"

    # ì˜ˆì•½ / ìŠ¤ì¼€ì¤„ë§
    if any(k in g for k in ["ì˜ˆì•½", "ìŠ¤ì¼€ì¤„", "ì˜ˆì•½ ì‹œìŠ¤í…œ", "booking", "book"]):
        return "ì˜ˆì•½/ìŠ¤ì¼€ì¤„ë§"

    # ì‡¼í•‘ / ì»¤ë¨¸ìŠ¤
    if any(k in g for k in ["ì‡¼í•‘", "ì»¤ë¨¸ìŠ¤", "ëª°", "ìŠ¤í† ì–´", "store", "shop", "commerce"]):
        return "ì‡¼í•‘/ì»¤ë¨¸ìŠ¤"

    # ê·¸ ì™¸ëŠ” ê³µí†µ íŒ¨í„´
    return "ê¸°íƒ€(ë²”ìš©)"


# ------------------------------------------------------------------------------------
# ì£¼ì œ ê¸°ë°˜ UI ì»´í¬ë„ŒíŠ¸ ì¶”ì²œ
# ------------------------------------------------------------------------------------
def recommend_components(goal: str) -> Tuple[str, List[Dict[str, str]]]:
    """ì•± ì£¼ì œë¥¼ ë¶„ë¥˜í•˜ê³ , í•´ë‹¹ ì£¼ì œì— ë§ëŠ” UI ì»´í¬ë„ŒíŠ¸ë¥¼ ì¶”ì²œí•œë‹¤."""
    topic = classify_goal(goal)

    # ì†Œê°œíŒ… / ë§¤ì¹­ ì„œë¹„ìŠ¤
    if topic == "ì†Œê°œíŒ…/ë§¤ì¹­":
        recs = [
            {"name": "í”„ë¡œí•„ ì¹´ë“œ", "desc": "ì‚¬ìš©ì ì •ë³´ë¥¼ ì¹´ë“œ í˜•íƒœë¡œ ë³´ì—¬ì£¼ëŠ” ì˜ì—­"},
            {"name": "ë§¤ì¹­ ëª©ë¡ í™”ë©´", "desc": "ì¶”ì²œ/ë§¤ì¹­ëœ ì‚¬ëŒë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³´ì—¬ì£¼ëŠ” í™”ë©´"},
            {"name": "ì±„íŒ… ë²„íŠ¼", "desc": "ì„ íƒí•œ ì‚¬ìš©ìì™€ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ëŠ” ë²„íŠ¼"},
            {"name": "ì¢‹ì•„ìš” ë²„íŠ¼", "desc": "ê´€ì‹¬ì„ í‘œì‹œí•˜ëŠ” í•˜íŠ¸/ì¢‹ì•„ìš” ë²„íŠ¼"},
            {"name": "í•„í„° ë°”", "desc": "ë‚˜ì´/ì§€ì—­ ë“± ê²€ìƒ‰ ì¡°ê±´ì„ ê³ ë¥´ëŠ” ì˜ì—­"},
            {"name": "í•˜ë‹¨ íƒ­ë°”", "desc": "í™ˆ/íƒìƒ‰/ì±„íŒ…/ë§ˆì´í˜ì´ì§€ë¡œ ì´ë™í•˜ëŠ” ë„¤ë¹„ê²Œì´ì…˜"},
        ]

    # ì˜ˆì•½ ì„œë¹„ìŠ¤
    elif topic == "ì˜ˆì•½/ìŠ¤ì¼€ì¤„ë§":
        recs = [
            {"name": "ìº˜ë¦°ë”", "desc": "ì˜ˆì•½ ë‚ ì§œë¥¼ ê³ ë¥´ëŠ” ìº˜ë¦°ë” UI"},
            {"name": "ì‹œê°„ ì„ íƒ ì˜ì—­", "desc": "ê°€ëŠ¥í•œ ì‹œê°„ì„ ì„ íƒí•˜ëŠ” ë²„íŠ¼/ë¦¬ìŠ¤íŠ¸"},
            {"name": "ì˜ˆì•½ ëª©ë¡ í™”ë©´", "desc": "ë‚´ ì˜ˆì•½ë“¤ì„ ëª¨ì•„ì„œ ë³´ì—¬ì£¼ëŠ” í™”ë©´"},
            {"name": "ì˜ˆì•½ ìƒì„¸ ì¹´ë“œ", "desc": "ì„ íƒí•œ ì˜ˆì•½ì˜ ìƒì„¸ ì •ë³´ë¥¼ ë³´ì—¬ì£¼ëŠ” ì¹´ë“œ"},
            {"name": "í™•ì¸/ì·¨ì†Œ ë²„íŠ¼", "desc": "ì˜ˆì•½ ìƒì„±/ë³€ê²½/ì·¨ì†Œë¥¼ í™•ì •í•˜ëŠ” ë²„íŠ¼"},
        ]

    # ì‡¼í•‘ / ì»¤ë¨¸ìŠ¤
    elif topic == "ì‡¼í•‘/ì»¤ë¨¸ìŠ¤":
        recs = [
            {"name": "ê²€ìƒ‰ì°½", "desc": "ìƒí’ˆ/ì¹´í…Œê³ ë¦¬ë¥¼ ê²€ìƒ‰í•˜ëŠ” ì…ë ¥ì°½"},
            {"name": "ìƒí’ˆ ì¹´ë“œ", "desc": "ì´ë¯¸ì§€, ì´ë¦„, ê°€ê²©ì´ ë“¤ì–´ê°„ ìƒí’ˆ ì¹´ë“œ"},
            {"name": "ìƒí’ˆ ìƒì„¸ í™”ë©´", "desc": "ì„ íƒí•œ ìƒí’ˆì˜ ìƒì„¸ ì •ë³´ í™”ë©´"},
            {"name": "ì¥ë°”êµ¬ë‹ˆ ë²„íŠ¼", "desc": "ìƒí’ˆì„ ì¥ë°”êµ¬ë‹ˆì— ë‹´ëŠ” ë²„íŠ¼"},
            {"name": "ê²°ì œ/ì£¼ë¬¸ ë²„íŠ¼", "desc": "ê²°ì œë¥¼ ì§„í–‰í•˜ëŠ” ë²„íŠ¼"},
            {"name": "ì¹´í…Œê³ ë¦¬ íƒ­", "desc": "ì¹´í…Œê³ ë¦¬ë³„ë¡œ ìƒí’ˆì„ ë‚˜ëˆ„ëŠ” íƒ­"},
        ]

    # ê¸°ë³¸ ì¶”ì²œ (ê¸°íƒ€/ë²”ìš©)
    else:
        recs = [
            {"name": "ìƒë‹¨ ì œëª©ë°”", "desc": "í™”ë©´ ì œëª©ì´ ë“¤ì–´ê°€ëŠ” ì˜ì—­"},
            {"name": "í…ìŠ¤íŠ¸ ì…ë ¥ì°½", "desc": "ê²€ìƒ‰/ì…ë ¥ì— ì‚¬ìš©í•˜ëŠ” ê¸°ë³¸ ì…ë ¥ì°½"},
            {"name": "í™•ì¸ ë²„íŠ¼", "desc": "ì£¼ìš” ë™ì‘ì„ ìˆ˜í–‰í•˜ëŠ” ê¸°ë³¸ ë²„íŠ¼"},
            {"name": "ë¦¬ìŠ¤íŠ¸ ì¹´ë“œ", "desc": "ì—¬ëŸ¬ í•­ëª©ì„ ì„¸ë¡œë¡œ ë‚˜ì—´í•˜ëŠ” ì¹´ë“œ ë¦¬ìŠ¤íŠ¸"},
            {"name": "í•˜ë‹¨ íƒ­ë°”", "desc": "ì—¬ëŸ¬ í™”ë©´ìœ¼ë¡œ ì´ë™í•˜ëŠ” ê³µí†µ ë„¤ë¹„ê²Œì´ì…˜"},
        ]

    return topic, recs

# ------------------------------------------------------------------------------------
# ì†ê·¸ë¦¼ â†’ ê°„ë‹¨ ì»´í¬ë„ŒíŠ¸ ê°ì§€
# ------------------------------------------------------------------------------------
def detect_components(image_bytes: bytes) -> List[UIComponent]:
    if cv2 is None or np is None:
        return [UIComponent("screen", "root", [0, 0, 512, 512])]

    try:
        arr = np.frombuffer(image_bytes, np.uint8)
        img = cv2.imdecode(arr, cv2.IMREAD_GRAYSCALE)
        if img is None:
            raise ValueError("ì´ë¯¸ì§€ ë””ì½”ë“œ ì‹¤íŒ¨")

        edges = cv2.Canny(img, 80, 180)
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        comps: List[UIComponent] = []
        for c in contours:
            x, y, w, h = cv2.boundingRect(c)
            if w * h < 800:
                continue
            comps.append(UIComponent("component", f"region_{len(comps)+1}", [int(x), int(y), int(x + w), int(y + h)]))

        if not comps:
            comps.append(UIComponent("screen", "root", [0, 0, img.shape[1], img.shape[0]]))
        return comps
    except Exception:
        return [UIComponent("screen", "root", [0, 0, 512, 512])]

# ------------------------------------------------------------------------------------
# LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
# ------------------------------------------------------------------------------------
def build_prompt(
    goal: str,
    goal_topic: str,
    selected_features: List[Dict[str, str]],
    selected_ui: List[Dict[str, str]],
    detected_components: List[UIComponent],
    refined_goal: Optional[str] = None,
    plan_outline: Optional[str] = None,
) -> str:
    feat_json = json.dumps(selected_features, ensure_ascii=False)
    ui_json = json.dumps(selected_ui, ensure_ascii=False)
    comp_json = json.dumps([asdict(c) for c in detected_components], ensure_ascii=False)
    final_goal = refined_goal.strip() if refined_goal else goal

    plan_section = ""
    if plan_outline:
        plan_section = f"""
[í˜„ì¬ ê³„íš ìš”ì•½]
{plan_outline}
"""

    return f"""
ë„ˆëŠ” í•œêµ­ì–´ë¥¼ ì‚¬ìš©í•˜ëŠ” ì†Œí”„íŠ¸ì›¨ì–´ ìš”êµ¬ì‚¬í•­ ë¶„ì„ê°€ì´ë‹¤.

[ì—­í• ]
- ì‚¬ìš©ìê°€ ë§Œë“¤ê³  ì‹¶ì€ ì•±ì˜ ëª©ì ê³¼ ê¸°ëŠ¥ì„ ì´í•´í•˜ê³ ,
- í•µì‹¬ ê¸°ëŠ¥ ìœ„ì£¼ì˜ **ìƒì„¸í•œ** ìš”êµ¬ì‚¬í•­ ëª…ì„¸ì„œ(í•œêµ­ì–´)ë¥¼ ì‘ì„±í•˜ë©°,
- í™”ë©´ íë¦„ì„ ê°„ë‹¨í•œ ASCII ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ì •ë¦¬í•œë‹¤.

[ì¶”ë¡  ë§¥ë½]
- ì›ë³¸ ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì£¼ì œ: "{goal}"
- ì •ì œëœ/ë³´ì •ëœ ëª©í‘œ: "{final_goal}"
- ê³„íš ê¸°ë°˜ ì¶”ë¡  ë©”ëª¨: ìœ„ [í˜„ì¬ ê³„íš ìš”ì•½]ì„ ì°¸ê³ í•œë‹¤.

[ì¶œë ¥ í˜•ì‹]
- JSON í•œ ê°œë§Œ ì¶œë ¥í•œë‹¤.
- ë°”ê¹¥ì— ì„¤ëª…, ë¬¸ì¥, ì½”ë“œë¸”ë¡, ë§ˆí¬ë‹¤ìš´ì„ ë¶™ì´ì§€ ë§ ê²ƒ.
- í‚¤ëŠ” ë‘ ê°œë§Œ ì‚¬ìš©í•œë‹¤.
  - "requirements_markdown": ë¬¸ìì—´ (Markdown í˜•ì‹, í•œêµ­ì–´)
  - "ascii_diagram": ë¬¸ìì—´ (ASCII ë‹¤ì´ì–´ê·¸ë¨, í­ 80ì ì´ë‚´)

ì˜ˆì‹œ (í˜•ì‹ë§Œ ì°¸ê³  â€“ ì‹¤ì œ ë‚´ìš©ì€ í›¨ì”¬ ê¸¸ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•  ê²ƒ):
<<JSON>>
{{
  "requirements_markdown": "# ê°œìš”\\n...ê¸´ ì„¤ëª…...\\n# ê¸°ëŠ¥ì  ìš”êµ¬ì‚¬í•­\\n...ì—¬ëŸ¬ í•­ëª©...\\n# ë¹„ê¸°ëŠ¥ì  ìš”êµ¬ì‚¬í•­\\n...ì—¬ëŸ¬ í•­ëª©...",
  "ascii_diagram": "[ì‚¬ìš©ì] --> (ë¡œê·¸ì¸ í™”ë©´)\\n(ë¡œê·¸ì¸ í™”ë©´) --> (í™ˆ í™”ë©´)\\n..."
}}
</JSON>

[ì…ë ¥ ì •ë³´]
- ì•±/ì„œë¹„ìŠ¤ ì£¼ì œ: "{goal}"
- ì•±/ì„œë¹„ìŠ¤ ë¶„ë¥˜: "{goal_topic}"

- ì‚¬ìš©ìê°€ ì„ íƒí•œ ì£¼ìš” ê¸°ëŠ¥ ëª©ë¡ (ì²´í¬ë°•ìŠ¤):
{feat_json}

- ì‚¬ìš©ìê°€ ì„ íƒí•œ ëŒ€í‘œì ì¸ UI ì»´í¬ë„ŒíŠ¸:
{ui_json}

- ì†ê·¸ë¦¼ì—ì„œ ê°ì§€ëœ ëŒ€ëµì ì¸ í™”ë©´ ì˜ì—­(ìˆìœ¼ë©´ ì°¸ê³ , ì—†ì–´ë„ ë¬´ì‹œ ê°€ëŠ¥):
{comp_json}

{plan_section}

[ì‘ì„± ì§€ì¹¨]
1) "requirements_markdown"
   - í•œêµ­ì–´ë¡œ ì‘ì„±í•œë‹¤.
   - ì „ì²´ ë¶„ëŸ‰ì€ ìµœì†Œ 500ì ì´ìƒìœ¼ë¡œ ì¶©ë¶„íˆ ìì„¸íˆ ì“´ë‹¤.
   - ëª¨ë“  ë‹¨ë½ê³¼ ëª©ë¡ì€ Markdownì˜ ë¶ˆë¦¿(`- `) ë˜ëŠ” ë²ˆí˜¸ ëª©ë¡(`FR-01`, `NFR-01`) í˜•ì‹ìœ¼ë¡œ í‘œê¸°í•´ ê°€ë…ì„±ì„ ë†’ì¸ë‹¤.
   - êµ¬ì¡° ì˜ˆ:
     - # ê°œìš”
       - ì„œë¹„ìŠ¤ ëª©ì , ì£¼ìš” íƒ€ê¹ƒ ì‚¬ìš©ì, í•´ê²°í•˜ê³ ì í•˜ëŠ” ë¬¸ì œë¥¼ 2~3ë¬¸ë‹¨ìœ¼ë¡œ ì„¤ëª….
       - ê° ë¬¸ë‹¨ì€ `-` ë¶ˆë¦¿ìœ¼ë¡œ ì‹œì‘í•˜ì—¬ í•µì‹¬ ë‚´ìš©ì„ ì§§ê²Œ ìš”ì•½í•œë‹¤.
     - # ê¸°ëŠ¥ì  ìš”êµ¬ì‚¬í•­
       - FR-01, FR-02 ì²˜ëŸ¼ ë²ˆí˜¸ë¥¼ ë¶™ì—¬ ë‚˜ì—´í•œë‹¤.
       - ê° FR í•­ëª© ì•„ë˜ì—ëŠ” 2~3ê°œì˜ í•˜ìœ„ ë¶ˆë¦¿ì„ ì‚¬ìš©í•´ ì…ë ¥/ì²˜ë¦¬/ì¶œë ¥, ì˜ˆì™¸ ì‚¬í•­ì„ ì •ë¦¬í•œë‹¤.
       - ìµœì†Œ 8ê°œ ì´ìƒì˜ ê¸°ëŠ¥ì  ìš”êµ¬ì‚¬í•­ì„ ì‘ì„±í•œë‹¤.
       - ì‚¬ìš©ìê°€ ì²´í¬í•œ ê¸°ëŠ¥ ëª©ë¡(feat_json)ì„ ëª¨ë‘ ë°˜ì˜í•˜ê³ ,
         ê° ê¸°ëŠ¥ì„ 1ê°œ ì´ìƒì˜ ìš”êµ¬ì‚¬í•­ìœ¼ë¡œ í’€ì–´ì„œ ì“´ë‹¤.
       - ì‚¬ìš©ìê°€ ì„ íƒí•œ UI ì»´í¬ë„ŒíŠ¸ ëª©ë¡(selected_ui)ì€ í™”ë©´ ì„¤ê³„ì˜ íŒíŠ¸ì´ë¯€ë¡œ, ìš”êµ¬ì‚¬í•­ ì„¤ëª…ê³¼ ASCII ë‹¤ì´ì–´ê·¸ë¨ì— ê°€ëŠ¥í•œ í•œ ë°˜ì˜í•œë‹¤.
     - # ë¹„ê¸°ëŠ¥ì  ìš”êµ¬ì‚¬í•­
       - NFR-01, NFR-02 í˜•ì‹ìœ¼ë¡œ ë²ˆí˜¸ë¥¼ ë¶™ì¸ë‹¤.
       - ê° NFRì—ë„ `-` ë¶ˆë¦¿ì„ í™œìš©í•´ ì¸¡ì • ì§€í‘œë‚˜ ì œì•½ì„ ëª…ì‹œí•œë‹¤.
       - ìµœì†Œ 5ê°œ ì´ìƒì˜ ë¹„ê¸°ëŠ¥ì  ìš”êµ¬ì‚¬í•­ì„ ì‘ì„±í•œë‹¤.
       - ì„±ëŠ¥(ì‘ë‹µ ì‹œê°„, ë™ì‹œ ì ‘ì† ìˆ˜), ë³´ì•ˆ(ì¸ì¦, ì¸ê°€, ë°ì´í„° ë³´í˜¸),
         í™•ì¥ì„±, ì‚¬ìš©ì„±(UX), ë¡œê·¸/ëª¨ë‹ˆí„°ë§, ë°±ì—”ë“œ API ì„¤ê³„ ê³ ë ¤ì‚¬í•­ ë“±ì„ í¬í•¨í•œë‹¤.

2) "ascii_diagram"
   - ì „ì²´ì ì¸ í™”ë©´/ê¸°ëŠ¥ íë¦„ì„ í™”ì‚´í‘œë¡œ í‘œí˜„í•œë‹¤.
   - ê´„í˜¸ì™€ í™”ì‚´í‘œë¥¼ ì‚¬ìš©í•´ ì´í•´í•˜ê¸° ì‰½ê²Œ í‘œí˜„í•œë‹¤.
   - ìµœì†Œ 5ì¤„ ì´ìƒ ì‘ì„±í•˜ë©°, ë‹¤ìŒ ìš”ì†Œë¥¼ í¬í•¨í•œë‹¤.
     - [ì‚¬ìš©ì]
     - (ë¡œê·¸ì¸ í™”ë©´) ë˜ëŠ” (ì‹œì‘ í™”ë©´)
     - (ë©”ì¸/í™ˆ í™”ë©´)
     - (ì£¼ìš” ëª©ë¡ í™”ë©´) ì˜ˆ: (ë§¤ì¹­ ëª©ë¡ í™”ë©´), (ì½˜í…ì¸  ëª©ë¡ í™”ë©´) ë“±
     - (ìƒì„¸ í™”ë©´)
   - ê°€ëŠ¥í•˜ë©´ ë°±ì—”ë“œ ì„œë²„ë„ í•¨ê»˜ í‘œí˜„í•œë‹¤. ì˜ˆ:
     [ì‚¬ìš©ì] --> (ë¡œê·¸ì¸ í™”ë©´)
     (ë¡œê·¸ì¸ í™”ë©´) --> (ë°±ì—”ë“œ API ì„œë²„: ì¸ì¦)
     (ë°±ì—”ë“œ API ì„œë²„: ì¸ì¦) --> (í™ˆ í™”ë©´)

3) ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•œë‹¤.
   - ë§¨ ì•ì— "<<JSON>>"
   - ë§¨ ë’¤ì— "</JSON>"
   - ê·¸ ì‚¬ì´ì—ëŠ” JSON í•œ ê°œë§Œ ì¡´ì¬
   - ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ ë„£ì§€ ë§ ê²ƒ.
   - ì½”ë“œë¸”ë¡(````), ì„¤ëª… ë¬¸ì¥, ì¤‘êµ­ì–´/ì˜ì–´ í•´ì„¤ ë“±ì€ ê¸ˆì§€.
"""


def build_reasoning_prompt(
    goal: str,
    selected_features: List[Dict[str, str]],
    selected_ui: List[Dict[str, str]],
    detected_components: List[UIComponent],
) -> str:
    feat_text = json.dumps(selected_features, ensure_ascii=False)
    ui_text = json.dumps(selected_ui, ensure_ascii=False)
    comp_text = json.dumps([asdict(c) for c in detected_components], ensure_ascii=False)
    return f"""
ë„ˆëŠ” ì†Œí”„íŠ¸ì›¨ì–´ ìš”êµ¬ì‚¬í•­ì„ ë¶„ì„í•˜ê¸° ìœ„í•œ ì„ í–‰ ë¸Œë ˆì¸ìŠ¤í† ë° ë´‡ì´ë‹¤.

ëª©í‘œ: ì‚¬ìš©ìê°€ ì œê³µí•œ ì…ë ¥ì„ ê²€í† í•˜ì—¬ í•µì‹¬ ëª©í‘œë¥¼ ì •ì œí•˜ê³ , í•„ìš”í•œ ì¶”ê°€ ì •ë³´ê°€ ìˆëŠ”ì§€ íŒë‹¨í•œ ë’¤ reasoning ë…¸íŠ¸ë¥¼ ì‘ì„±í•œë‹¤.

[ì…ë ¥]
- ì›ë³¸ ëª©í‘œ: "{goal}"
- ê¸°ëŠ¥ ì„ íƒ: {feat_text}
- UI ì»´í¬ë„ŒíŠ¸ ì„ íƒ: {ui_text}
- ê°ì§€ëœ ì»´í¬ë„ŒíŠ¸: {comp_text}

[ì¶œë ¥ í˜•ì‹]
JSONë§Œ ì¶œë ¥í•˜ë©°, ë‹¤ìŒ í‚¤ë¥¼ í¬í•¨í•œë‹¤:
{{
  "sanitized_goal": "í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ì œëœ ëª©í‘œ",
  "reasoning_summary": "Chain-of-Thought í˜•ì‹ì˜ ìš”ì•½ (3ë¬¸ì¥ ì´ìƒ)",
  "info_requests": ["ì¶”ê°€ë¡œ í•„ìš”í•œ ì •ë³´ ëª©ë¡. ì—†ìœ¼ë©´ []"]
}}
"""


def build_plan_prompt(
    sanitized_goal: str,
    selected_features: List[Dict[str, str]],
    selected_ui: List[Dict[str, str]],
    reasoning_notes: str,
    observations: List[str],
) -> str:
    feat_text = json.dumps(selected_features, ensure_ascii=False)
    ui_text = json.dumps(selected_ui, ensure_ascii=False)
    obs_text = "\\n".join(observations[-3:]) if observations else "ì—†ìŒ"
    return f"""
ë„ˆëŠ” SRS ìƒì„±ì„ ìœ„í•œ ê³„íšê°€ë‹¤.

[ì…ë ¥ ì •ë³´]
- ì •ì œëœ ëª©í‘œ: "{sanitized_goal}"
- ì„ íƒ ê¸°ëŠ¥: {feat_text}
- ì„ íƒ UI: {ui_text}
- ìµœì‹  ì¶”ë¡ /ê´€ì°° ë…¸íŠ¸: {obs_text}
- ì°¸ê³  Reasoning: {reasoning_notes}

[ì¶œë ¥ í˜•ì‹]
JSONë§Œ ì¶œë ¥í•œë‹¤:
{{
  "plan_title": "ê³„íš ì´ë¦„",
  "plan_summary": "ê³„íš ìš”ì•½ (3ë¬¸ì¥ ì´ìƒ)",
  "steps": [
    {{"id": "P1", "objective": "ì„¸ë¶€ ëª©í‘œ", "actions": ["í–‰ë™1", "í–‰ë™2"], "expected_outputs": ["ìš”êµ¬ì‚¬í•­ ì„¹ì…˜", "ë‹¤ì´ì–´ê·¸ë¨ ê°œì„  í¬ì¸íŠ¸"]}}
  ]
}}
ë‹¨, stepsëŠ” ìµœì†Œ 3ê°œ ì´ìƒ ì‘ì„±í•œë‹¤.
"""


def build_plan_revision_prompt(
    sanitized_goal: str,
    previous_plan: str,
    errors: List[str],
    observations: List[str],
) -> str:
    obs_text = "\\n".join(observations[-5:]) if observations else "ì—†ìŒ"
    err_text = "\\n".join(errors) if errors else "ì—†ìŒ"
    return f"""
ë„ˆëŠ” ì‹¤íŒ¨í•œ ê³„íšì„ ê°œì„ í•˜ëŠ” ì½”ì¹˜ì´ë‹¤.

[ëª©í‘œ]
- ì •ì œëœ ëª©í‘œ: "{sanitized_goal}"
- ì´ì „ ê³„íš(JSON): {previous_plan}
- ìµœê·¼ ê´€ì°°: {obs_text}
- ë°œìƒí•œ ì˜¤ë¥˜/ê²€ì¦ ë¬¸ì œ: {err_text}

[ì¶œë ¥]
JSONë§Œ ë°˜í™˜í•˜ë©°, ë‹¤ìŒ í‚¤ë¥¼ í¬í•¨í•œë‹¤:
{{
  "plan_title": "ì—…ë°ì´íŠ¸ëœ ê³„íš ì´ë¦„",
  "plan_summary": "ìˆ˜ì • ìš”ì•½ (2ë¬¸ë‹¨)",
  "steps": [
    {{"id": "R1", "objective": "ê°œì„  í¬ì¸íŠ¸", "actions": ["..."], "expected_outputs": ["..."]}}
  ]
}}
stepsëŠ” ìµœì†Œ 2ê°œ ì´ìƒ ì‘ì„±í•˜ê³ , ì´ì „ ì˜¤ë¥˜ë¥¼ ì–´ë–»ê²Œ ë‹¤ë£°ì§€ actionsì— ëª…ì‹œí•œë‹¤.
"""


# ------------------------------------------------------------------------------------
# JSON ì¶”ì¶œ & ë³µêµ¬ ë¡œì§ (Qwenì´ ì´ìƒí•˜ê²Œ ë§í•´ë„ ìµœëŒ€í•œ ì‚´ë ¤ë‚´ê¸°)
# ------------------------------------------------------------------------------------
def _find_first_valid_json(text: str) -> Dict[str, Any]:
    # ì½”ë“œë¸”ë¡ ì œê±°
    text = text.replace("```json", "").replace("```", "").strip()

    # ëª¨ë“  ìœ„ì¹˜ì—ì„œ { ... } í›„ë³´ë¥¼ ì°¾ì•„ë³´ë©° íŒŒì‹± ì‹œë„
    for start_idx, ch in enumerate(text):
        if ch != "{":
            continue
        for end_idx in range(len(text) - 1, start_idx, -1):
            if text[end_idx] != "}":
                continue
            candidate = text[start_idx : end_idx + 1]
            try:
                obj = json.loads(candidate)
                return obj
            except Exception:
                continue
    # ì‹¤íŒ¨
    raise json.JSONDecodeError("No valid JSON object found", text, 0)


def _decode_jsonish_string(value: str) -> str:
    try:
        return bytes(value, "utf-8").decode("unicode_escape")
    except Exception:
        return value.replace("\\n", "\n").replace("\\t", "\t")


def _recover_jsonish_fields(text: str) -> Optional[Dict[str, Any]]:
    def _extract(label: str) -> Optional[str]:
        token = f'"{label}"'
        start = text.find(token)
        if start == -1:
            return None
        colon = text.find(":", start + len(token))
        if colon == -1:
            return None
        quote = text.find('"', colon)
        if quote == -1:
            return None
        buf = []
        escaped = False
        i = quote + 1
        while i < len(text):
            ch = text[i]
            if escaped:
                buf.append(ch)
                escaped = False
            elif ch == "\\":
                escaped = True
            elif ch == '"':
                break
            else:
                buf.append(ch)
            i += 1
        if not buf:
            return None
        return "".join(buf)

    rm_raw = _extract("requirements_markdown")
    ad_raw = _extract("ascii_diagram")
    recovered: Dict[str, Any] = {}
    if rm_raw:
        recovered["requirements_markdown"] = _decode_jsonish_string(rm_raw)
    if ad_raw:
        recovered["ascii_diagram"] = _decode_jsonish_string(ad_raw)
    return recovered or None


def extract_json(text: str) -> Dict[str, Any]:
    start_tag = "<<JSON>>"
    end_tag = "</JSON>"
    if start_tag in text and end_tag in text:
        start = text.find(start_tag) + len(start_tag)
        end = text.find(end_tag, start)
        text = text[start:end].strip()

    try:
        obj = _find_first_valid_json(text)
    except json.JSONDecodeError:
        recovered = _recover_jsonish_fields(text)
        if recovered:
            return recovered
        # ì™„ì „íˆ ì‹¤íŒ¨í•˜ë©´ í†µì§¸ë¡œ requirementsì— ë„£ì–´ë‘”ë‹¤
        return {
            "requirements_markdown": text.replace("<<JSON>>", "").replace("</JSON>", "").strip(),
            "ascii_diagram": "(LLM JSON íŒŒì‹± ì‹¤íŒ¨: ìœ„ í…ìŠ¤íŠ¸ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì •ë¦¬í•´ì•¼ í•¨)",
        }

    # Qwenì´ JSON ì•ˆì— JSON ë¬¸ìì—´ì„ ë‹¤ì‹œ ë„£ëŠ” ê²½ìš° ì²˜ë¦¬
    rm = obj.get("requirements_markdown")
    ad = obj.get("ascii_diagram")

    # requirements_markdownì´ ë‹¤ì‹œ JSON ë¬¸ìì—´ì¼ ë•Œ
    if isinstance(rm, str) and rm.strip().startswith("{") and '"requirements_markdown"' in rm:
        try:
            inner = json.loads(rm)
            if "requirements_markdown" in inner:
                obj["requirements_markdown"] = inner["requirements_markdown"]
            if "ascii_diagram" in inner and not ad:
                obj["ascii_diagram"] = inner["ascii_diagram"]
        except Exception:
            pass

    # ascii_diagramì´ JSON ë¬¸ìì—´ì¸ ê²½ìš°
    if isinstance(ad, str) and ad.strip().startswith("{") and '"ascii_diagram"' in ad:
        try:
            inner = json.loads(ad)
            if "ascii_diagram" in inner:
                obj["ascii_diagram"] = inner["ascii_diagram"]
        except Exception:
            pass

    # ìµœì¢… safety
    if "requirements_markdown" not in obj:
        obj["requirements_markdown"] = "(requirements_markdown ëˆ„ë½)"
    if "ascii_diagram" not in obj:
        obj["ascii_diagram"] = "(ascii_diagram ëˆ„ë½)"

    return obj


def safe_parse_json_block(text: str) -> Dict[str, Any]:
    try:
        return _find_first_valid_json(text)
    except json.JSONDecodeError:
        return {"raw_text": text}


def format_plan_outline(plan_obj: Dict[str, Any]) -> str:
    try:
        return json.dumps(plan_obj, ensure_ascii=False, indent=2)
    except Exception:
        return str(plan_obj)


def requirement_quality_tool(text: str) -> Dict[str, Any]:
    """ê°„ë‹¨í•œ í’ˆì§ˆ ê²€ì‚¬ë¥¼ ìˆ˜í–‰í•˜ëŠ” ë‚´ë¶€ íˆ´."""
    length = len(text or "")
    sections = [line for line in (text or "").splitlines() if line.startswith("#")]
    passed = length >= 500 and len(sections) >= 3
    return {
        "tool": "requirement_quality",
        "length": length,
        "section_count": len(sections),
        "passed": passed,
        "details": "ë¶„ëŸ‰>=500 & ì„¹ì…˜ 3ê°œ ì´ìƒ" if passed else "ë¶„ëŸ‰/ì„¹ì…˜ ê¸°ì¤€ ë¯¸ë‹¬",
    }


def ascii_diagram_quality_tool(diagram: str) -> Dict[str, Any]:
    lines = [line for line in (diagram or "").splitlines() if line.strip()]
    includes_required = all(k in diagram for k in ["[ì‚¬ìš©ì]", "(ë¡œê·¸ì¸", "(í™ˆ", "(ìƒì„¸"])
    passed = len(lines) >= 5 and includes_required
    return {
        "tool": "ascii_diagram_quality",
        "line_count": len(lines),
        "includes_required": includes_required,
        "passed": passed,
        "details": "ë¼ì¸>=5 & í•„ìˆ˜ ë…¸ë“œ í¬í•¨" if passed else "ë‹¤ì´ì–´ê·¸ë¨ ê¸°ì¤€ ë¯¸ë‹¬",
    }


def capture_gpu_metrics(stage: str) -> Dict[str, Any]:
    metric: Dict[str, Any] = {"stage": stage}
    if torch.cuda.is_available():
        device = torch.cuda.current_device()
        allocated = torch.cuda.memory_allocated(device) / (1024 ** 2)
        reserved = torch.cuda.memory_reserved(device) / (1024 ** 2)
        max_alloc = torch.cuda.max_memory_allocated(device) / (1024 ** 2)
        metric.update(
            {
                "device": f"cuda:{device}",
                "allocated_mb": round(allocated, 2),
                "reserved_mb": round(reserved, 2),
                "max_allocated_mb": round(max_alloc, 2),
            }
        )
    else:
        metric.update({"device": "cpu", "note": "CUDA unavailable"})
    return metric


def record_gpu_metric(state: RequirementState, stage: str) -> None:
    metric = capture_gpu_metrics(stage)
    state.setdefault("gpu_metrics", []).append(metric)


# ------------------------------------------------------------------------------------
# LangGraph ì›Œí¬í”Œë¡œ êµ¬ì„±
# ------------------------------------------------------------------------------------
def _run_llm(prompt: str) -> str:
    tokenizer, model = load_model()
    return model_generate(prompt, tokenizer, model)


def collect_inputs_node(state: RequirementState) -> RequirementState:
    """Streamlit ì„¸ì…˜ì—ì„œ ë°›ì€ ì…ë ¥ì„ LangGraph ìƒíƒœì— ì •ë¦¬í•œë‹¤."""
    goal = state.get("goal", "").strip()
    state["goal"] = goal
    state["goal_topic"] = state.get("goal_topic") or classify_goal(goal)
    state.setdefault("selected_features", [])
    state.setdefault("selected_ui", [])
    state.setdefault("detected_components", [])
    state.setdefault("observations", [])
    state.setdefault("actions_taken", [])
    state["errors"] = []
    state.setdefault("tool_reports", [])
    state.setdefault("gpu_metrics", [])
    state["retry_count"] = state.get("retry_count", 0)
    return state


def reasoning_node(state: RequirementState) -> RequirementState:
    prompt = build_reasoning_prompt(
        goal=state.get("goal", ""),
        selected_features=state.get("selected_features", []),
        selected_ui=state.get("selected_ui", []),
        detected_components=state.get("detected_components", []),
    )
    record_gpu_metric(state, "reasoning_before")
    raw = _run_llm(prompt)
    record_gpu_metric(state, "reasoning_after")
    parsed = safe_parse_json_block(raw)
    sanitized_goal = parsed.get("sanitized_goal") or state.get("goal", "")
    state["sanitized_goal"] = sanitized_goal
    state["reasoning_notes"] = parsed.get("reasoning_summary", raw)
    state["info_requests"] = parsed.get("info_requests", [])
    state.setdefault("observations", []).append(f"Reasoning: {state['reasoning_notes']}")
    if state["info_requests"]:
        state["observations"].append(f"ì¶”ê°€ ì •ë³´ í•„ìš”: {state['info_requests']}")
    state.setdefault("actions_taken", []).append("reasoning")
    return state


def plan_builder_node(state: RequirementState) -> RequirementState:
    prompt = build_plan_prompt(
        sanitized_goal=state.get("sanitized_goal", state.get("goal", "")),
        selected_features=state.get("selected_features", []),
        selected_ui=state.get("selected_ui", []),
        reasoning_notes=state.get("reasoning_notes", ""),
        observations=state.get("observations", []),
    )
    record_gpu_metric(state, "plan_builder_before")
    raw = _run_llm(prompt)
    record_gpu_metric(state, "plan_builder_after")
    plan_obj = safe_parse_json_block(raw)
    state["plan_outline"] = plan_obj
    state["plan_text"] = format_plan_outline(plan_obj)
    state.setdefault("actions_taken", []).append("plan_builder")
    return state


def plan_revision_node(state: RequirementState) -> RequirementState:
    prompt = build_plan_revision_prompt(
        sanitized_goal=state.get("sanitized_goal", state.get("goal", "")),
        previous_plan=state.get("plan_text", ""),
        errors=state.get("errors", []),
        observations=state.get("observations", []),
    )
    record_gpu_metric(state, "plan_revision_before")
    raw = _run_llm(prompt)
    record_gpu_metric(state, "plan_revision_after")
    plan_obj = safe_parse_json_block(raw)
    state["plan_outline"] = plan_obj
    state["plan_text"] = format_plan_outline(plan_obj)
    state.setdefault("actions_taken", []).append("plan_revision")
    state["errors"] = []
    return state


def action_prompt_builder_node(state: RequirementState) -> RequirementState:
    state["errors"] = []
    plan_text = state.get("plan_text", "")
    state["action_prompt"] = build_prompt(
        goal=state.get("goal", ""),
        goal_topic=state.get("goal_topic", "ê¸°íƒ€(ë²”ìš©)"),
        selected_features=state.get("selected_features", []),
        selected_ui=state.get("selected_ui", []),
        detected_components=state.get("detected_components", []),
        refined_goal=state.get("sanitized_goal"),
        plan_outline=plan_text,
    )
    state.setdefault("actions_taken", []).append("action_prompt_builder")
    return state


def llm_call_node(state: RequirementState) -> RequirementState:
    """ë¡œì»¬ Qwen ëª¨ë¸ì„ í˜¸ì¶œí•œë‹¤."""
    record_gpu_metric(state, "action_llm_before")
    state["llm_output"] = _run_llm(state.get("action_prompt", ""))
    record_gpu_metric(state, "action_llm_after")
    state.setdefault("actions_taken", []).append("action_llm")
    return state


def json_validator_node(state: RequirementState) -> RequirementState:
    """LLM ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•˜ê³  í•„ìˆ˜ í‚¤ë¥¼ ê²€ì¦í•œë‹¤."""
    parsed = extract_json(state.get("llm_output", ""))
    state["parsed_json"] = parsed
    missing = []
    if not parsed.get("requirements_markdown"):
        missing.append("requirements_markdown")
    if not parsed.get("ascii_diagram"):
        missing.append("ascii_diagram")
    if missing:
        state.setdefault("errors", []).append(f"Missing keys: {missing}")
    state.setdefault("actions_taken", []).append("json_validator")
    return state


def tool_evaluation_node(state: RequirementState) -> RequirementState:
    parsed = state.get("parsed_json", {})
    req = parsed.get("requirements_markdown", "")
    diag = parsed.get("ascii_diagram", "")
    reports = [
        requirement_quality_tool(req),
        ascii_diagram_quality_tool(diag),
    ]
    state["tool_reports"] = reports
    failed = [r for r in reports if not r.get("passed")]
    if failed:
        state.setdefault("errors", []).append(f"Tool checks failed: {failed}")
    state.setdefault("observations", []).append(f"Tool reports: {reports}")
    state.setdefault("actions_taken", []).append("tool_evaluation")
    return state


def postprocess_node(state: RequirementState) -> RequirementState:
    """Streamlit UIì— ë³´ì—¬ì¤„ ìµœì¢… ë°ì´í„°ë¥¼ êµ¬ì„±í•œë‹¤."""
    parsed = state.get("parsed_json", {})
    requirements = parsed.get("requirements_markdown", "(ìƒì„± ì‹¤íŒ¨)").strip()
    diagram = parsed.get("ascii_diagram", "(ìƒì„± ì‹¤íŒ¨)").strip()
    state["result_payload"] = {
        "requirements_markdown": requirements,
        "ascii_diagram": diagram,
        "debug_raw": parsed,
        "errors": state.get("errors", []),
        "plan": state.get("plan_outline", {}),
        "sanitized_goal": state.get("sanitized_goal", ""),
        "reasoning_notes": state.get("reasoning_notes", ""),
        "info_requests": state.get("info_requests", []),
        "actions_taken": state.get("actions_taken", []),
        "observations": state.get("observations", []),
        "tool_reports": state.get("tool_reports", []),
        "gpu_metrics": state.get("gpu_metrics", []),
    }
    state.setdefault("actions_taken", []).append("postprocess")
    return state


def observe_and_route_node(state: RequirementState) -> RequirementState:
    errors = state.get("errors", [])
    if errors:
        state.setdefault("observations", []).append(f"ê²€ì¦ ì˜¤ë¥˜: {errors}")
    else:
        state.setdefault("observations", []).append("ê²€ì¦ í†µê³¼: ëª¨ë“  í•„ìˆ˜ í‚¤ ìƒì„±")
    retry_count = state.get("retry_count", 0)
    should_retry = bool(errors) and retry_count < MAX_AGENT_RETRIES
    state["should_retry"] = should_retry
    if should_retry:
        state["retry_count"] = retry_count + 1
    state.setdefault("actions_taken", []).append("observe")
    return state


def decide_next_step(state: RequirementState) -> str:
    return "retry" if state.get("should_retry") else "finish"


@st.cache_resource
def build_requirements_workflow():
    graph = StateGraph(RequirementState)
    graph.add_node("collect_inputs", collect_inputs_node)
    graph.add_node("reasoning", reasoning_node)
    graph.add_node("plan_builder", plan_builder_node)
    graph.add_node("action_prompt_builder", action_prompt_builder_node)
    graph.add_node("local_llm", llm_call_node)
    graph.add_node("json_validator", json_validator_node)
    graph.add_node("tool_evaluation", tool_evaluation_node)
    graph.add_node("postprocess", postprocess_node)
    graph.add_node("observe", observe_and_route_node)
    graph.add_node("plan_revision", plan_revision_node)

    graph.set_entry_point("collect_inputs")
    graph.add_edge("collect_inputs", "reasoning")
    graph.add_edge("reasoning", "plan_builder")
    graph.add_edge("plan_builder", "action_prompt_builder")
    graph.add_edge("plan_revision", "action_prompt_builder")
    graph.add_edge("action_prompt_builder", "local_llm")
    graph.add_edge("local_llm", "json_validator")
    graph.add_edge("json_validator", "tool_evaluation")
    graph.add_edge("tool_evaluation", "postprocess")
    graph.add_edge("postprocess", "observe")
    graph.add_conditional_edges(
        "observe",
        decide_next_step,
        {
            "retry": "plan_revision",
            "finish": END,
        },
    )
    return graph.compile()


# ------------------------------------------------------------------------------------
# Streamlit UI
# ------------------------------------------------------------------------------------
def main():
    st.set_page_config(
        page_title="SketchToSpec",
        page_icon="ğŸ–Œï¸",
        layout="wide",
        initial_sidebar_state="expanded",
    )

    # ìŠ¤íƒ€ì¼ ì¶”ê°€
    st.markdown(
        """
        <style>
        .stButton > button {
            background-color: #4CAF50;
            color: white;
            font-size: 16px;
            padding: 10px 20px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
        }
        .stButton > button:hover {
            background-color: #45a049;
        }
        .stHeader {
            font-family: 'Arial', sans-serif;
            color: #333;
            text-align: center;
            margin-bottom: 20px;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )

    # Home ë²„íŠ¼ ì²˜ë¦¬ìš© í•¨ìˆ˜
    def reset_app():
        st.session_state.clear()
        st.rerun()

    if "home" not in st.session_state:
        st.session_state["home"] = True

    # ------------------------------
    # í™ˆ í™”ë©´
    # ------------------------------
    if st.session_state["home"]:
        # Hero Section
        st.markdown(
            """
            <div style="text-align:center; padding-top:40px; padding-bottom:20px;">
                <h1 style="font-size:40px; margin-bottom:10px;">SketchToSpec</h1>
                <p style="font-size:18px; color:#555; margin-bottom:4px;">
                    ì†ê·¸ë¦¼ê³¼ í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ ì†Œí”„íŠ¸ì›¨ì–´ ìš”êµ¬ì‚¬í•­ ë¬¸ì„œë¥¼ ìë™ ìƒì„±í•˜ëŠ” ë„êµ¬
                </p>
                <p style="font-size:15px; color:#888; margin-top:0;">
                    ì•„ì´ë””ì–´ Â· ê¸°ëŠ¥ ì²´í¬ë¦¬ìŠ¤íŠ¸ Â· í™”ë©´ ìŠ¤ì¼€ì¹˜ë¥¼ ì¡°í•©í•´
                    <br/>
                    ë°±ì—”ë“œ ì¹œí™”ì ì¸ ìš”êµ¬ì‚¬í•­ ëª…ì„¸ì™€ í™”ë©´ íë¦„ ë‹¤ì´ì–´ê·¸ë¨ì„ ìƒì„±í•œë‹¤.
                </p>
            </div>
            """,
            unsafe_allow_html=True,
        )

        st.markdown("---")

        # 5ë‹¨ê³„ Progress Guide ì¹´ë“œ UI
        st.markdown("### SketchToSpec ì‚¬ìš© íë¦„")

        col1, col2, col3 = st.columns(3)
        with col1:
            st.info(
                "**1. ì•± ì£¼ì œ ì…ë ¥**\n"
                "ë§Œë“¤ê³  ì‹¶ì€ ì•±ì˜ ëª©ì ê³¼ íƒ€ê¹ƒ ì‚¬ìš©ìë¥¼ í•œ ì¤„ë¡œ ì‘ì„±í•œë‹¤."
            )
        with col2:
            st.info(
                "**2. ê¸°ëŠ¥ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì„ íƒ**\n"
                "ë¡œê·¸ì¸, í”„ë¡œí•„, ëª©ë¡, ê²€ìƒ‰ ë“± ê³µí†µ ê¸°ëŠ¥ì„ ì²´í¬ë°•ìŠ¤ë¡œ ì„ íƒí•œë‹¤."
            )
        with col3:
            st.info(
                "**3. UI ì»´í¬ë„ŒíŠ¸ ì„ íƒ**\n"
                "í”„ë¡œí•„ ì¹´ë“œ, ë§¤ì¹­ ëª©ë¡, í•„í„° ë°” ê°™ì€ ëŒ€í‘œ í™”ë©´ ìš”ì†Œë¥¼ ê³ ë¥¸ë‹¤."
            )

        col4, col5 = st.columns(2)
        with col4:
            st.info(
                "**4. ì†ê·¸ë¦¼ ì—…ë¡œë“œ (ì„ íƒ)**\n"
                "ì¢…ì´ì— ê·¸ë¦° í™”ë©´ ìŠ¤ì¼€ì¹˜ë¥¼ ì‚¬ì§„ìœ¼ë¡œ ì—…ë¡œë“œí•´ ëŒ€ëµì ì¸ ë ˆì´ì•„ì›ƒ íŒíŠ¸ë¥¼ ì¤€ë‹¤."
            )
        with col5:
            st.info(
                "**5. ìš”êµ¬ì‚¬í•­ & ASCII ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±**\n"
                "LLMì´ ê¸°ëŠ¥/í™”ë©´ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìš”êµ¬ì‚¬í•­ ë¬¸ì„œì™€ í™”ë©´ íë¦„ ë‹¤ì´ì–´ê·¸ë¨ì„ ìƒì„±í•œë‹¤."
            )

        st.markdown("---")

        # ê°€ìš´ë° ì •ë ¬ëœ ì‹œì‘ ë²„íŠ¼
        spacer_left, center, spacer_right = st.columns([1, 1, 1])
        with center:
            if st.button("ì§€ê¸ˆ ì‹œì‘í•˜ê¸°", type="primary", use_container_width=True):
                st.session_state["home"] = False
                st.rerun()

    # ------------------------------
    # ì‹¤ì œ ì•± ê¸°ëŠ¥ í™”ë©´
    # ------------------------------
    else:
        st.header("ì•± ê¸°ëŠ¥")
        if st.button("í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
            reset_app()

        # ì„¸ì…˜ ì´ˆê¸°í™”
        st.session_state.setdefault("goal", "")
        st.session_state.setdefault("selected_features", [])  # ê¸°ëŠ¥ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì„ íƒ ê²°ê³¼
        st.session_state.setdefault("selected_ui", [])        # UI ì»´í¬ë„ŒíŠ¸ ì„ íƒ ê²°ê³¼
        st.session_state.setdefault("image_bytes", None)
        st.session_state.setdefault("detected_components", [])
        st.session_state.setdefault("current_step", 1)        # ë‹¨ê³„ë³„ ì§„í–‰ ìƒíƒœ

        # ìƒë‹¨ ì„¤ëª…
        st.title("SketchToSpec")
        st.caption("ì•± ì£¼ì œ + ìì£¼ ì“°ëŠ” ê¸°ëŠ¥ + í™”ë©´ ìš”ì†Œ + ì†ê·¸ë¦¼ì„ ë°”íƒ•ìœ¼ë¡œ ìš”êµ¬ì‚¬í•­ ë¬¸ì„œë¥¼ ë§Œë“¤ì–´ì£¼ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.")

        st.markdown(
            """
    **ì‚¬ìš© ë°©ë²•**

    1. ë§Œë“¤ê³  ì‹¶ì€ ì•±ì˜ ì£¼ì œë¥¼ ì ìŠµë‹ˆë‹¤.  
    2. ì´ ì•±ì— ë“¤ì–´ê°ˆ ë²•í•œ "ê¸°ëŠ¥"ì„ ì²´í¬ë°•ìŠ¤ë¡œ ê³ ë¦…ë‹ˆë‹¤.  
    3. (ì„ íƒ) ì£¼ì œì— ë§ëŠ” UI ìš”ì†Œë¥¼ ì¶”ì²œë°›ê³  ì„ íƒí•©ë‹ˆë‹¤.  
    4. (ì„ íƒ) ì†ê·¸ë¦¼ ìŠ¤ì¼€ì¹˜ë¥¼ ì—…ë¡œë“œí•©ë‹ˆë‹¤.  
    5. ìš”êµ¬ì‚¬í•­ & í™”ë©´ íë¦„ ë‹¤ì´ì–´ê·¸ë¨ì„ ìƒì„±í•©ë‹ˆë‹¤.
            """
        )

        # ------------------------------
        # ë‹¨ê³„ë³„ UI íë¦„
        # ------------------------------
        current_step = st.session_state.get("current_step", 1)

        if current_step == 1:
            st.subheader("1ë‹¨ê³„: ì£¼ì œ & ê¸°ëŠ¥ ì„ íƒ")
            goal = st.text_input(
                "ì–´ë–¤ ì•±ì„ ë§Œë“¤ê³  ì‹¶ë‚˜ìš”?",
                value=st.session_state.get("goal", ""),
                placeholder="ì˜ˆ) ëŒ€í•™ìƒì„ ìœ„í•œ ì†Œê°œíŒ… ë§¤ì¹­ ì•±",
            )
            st.session_state["goal"] = goal.strip()

            st.markdown("---")
            st.subheader("ì´ ì•±ì— í•„ìš”í•œ ê¸°ëŠ¥ë“¤ì„ ê³¨ë¼ë³´ì„¸ìš”")
            selected_features = []

            for category in sorted({f["category"] for f in FEATURE_LIBRARY}):
                with st.expander(f"ì¹´í…Œê³ ë¦¬: {category}", expanded=(category in ["ì¸ì¦/ê³„ì •", "ì½˜í…ì¸ "])):
                    for feat in [f for f in FEATURE_LIBRARY if f["category"] == category]:
                        key = f"feat_{feat['key']}"
                        initial = any(sf["key"] == feat["key"] for sf in st.session_state.get("selected_features", []))
                        checked = st.checkbox(
                            f"{feat['name']} Â· {feat['desc']}",
                            key=key,
                            value=initial,
                        )
                        if checked:
                            selected_features.append(feat)

            st.session_state["selected_features"] = selected_features

            if st.button("ë‹¤ìŒ ë‹¨ê³„ë¡œ"):
                st.session_state["current_step"] = 2
                st.rerun()

        elif current_step == 2:
            st.subheader("2ë‹¨ê³„: UI ì»´í¬ë„ŒíŠ¸ ì¶”ì²œ")

            goal = st.session_state.get("goal", "")
            if not goal:
                st.warning("1ë‹¨ê³„ì—ì„œ ì•± ì£¼ì œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
                if st.button("ì´ì „ ë‹¨ê³„ë¡œ"):
                    st.session_state["current_step"] = 1
                    st.rerun()
            else:
                # ì£¼ì œ ë¶„ë¥˜ + ì¶”ì²œ
                topic_label, recs = recommend_components(goal)
                st.session_state["goal_topic"] = topic_label  # í•„ìš”í•˜ë©´ ì´í›„ í”„ë¡¬í”„íŠ¸ì—ë„ ì‚¬ìš© ê°€ëŠ¥

                # ë¶„ë¥˜ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì£¼ê¸°
                if topic_label == "ê¸°íƒ€(ë²”ìš©)":
                    st.info(
                        f"ì•± ì£¼ì œë¥¼ ë³„ë„ ë„ë©”ì¸ìœ¼ë¡œ ì¸ì‹í•˜ì§€ ëª»í•´ **{topic_label}**ìœ¼ë¡œ ë¶„ë¥˜í–ˆì–´ìš”.\n"
                        f"ì•„ë˜ëŠ” ë‹¤ì–‘í•œ ì„œë¹„ìŠ¤ì— ê³µí†µìœ¼ë¡œ ì“¸ ìˆ˜ ìˆëŠ” UI ì»´í¬ë„ŒíŠ¸ ì¶”ì²œì…ë‹ˆë‹¤."
                    )
                else:
                    st.info(
                        f"ì•± ì£¼ì œë¥¼ **{topic_label}** ì£¼ì œë¡œ ë¶„ë¥˜í–ˆê³ , "
                        f"ì´ì— ê¸°ë°˜í•˜ì—¬ ì•„ë˜ UI ì»´í¬ë„ŒíŠ¸ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤."
                    )

                st.write("ì´ ì•±ì— ë“¤ì–´ê°ˆ ë²•í•œ í™”ë©´ ìš”ì†Œë“¤ì„ ê³¨ë¼ë³´ì„¸ìš”. (ì„ íƒ ì‚¬í•­)")

                selected_ui = []
                for comp in recs:
                    key = f"ui_{comp['name']}"
                    initial = any(c["name"] == comp["name"] for c in st.session_state.get("selected_ui", []))
                    checked = st.checkbox(
                        f"{comp['name']} Â· {comp['desc']}",
                        key=key,
                        value=initial,
                    )
                    if checked:
                        selected_ui.append(comp)

                st.session_state["selected_ui"] = selected_ui

                if st.button("ë‹¤ìŒ ë‹¨ê³„ë¡œ"):
                    st.session_state["current_step"] = 3
                    st.rerun()
                if st.button("ì´ì „ ë‹¨ê³„ë¡œ"):
                    st.session_state["current_step"] = 1
                    st.rerun()

        elif current_step == 3:
            st.subheader("3ë‹¨ê³„: ì†ê·¸ë¦¼ ì—…ë¡œë“œ")

            uploaded = st.file_uploader("PNG/JPG íŒŒì¼ ì—…ë¡œë“œ", type=["png", "jpg", "jpeg"])
            if uploaded:
                image_bytes = uploaded.read()
                st.session_state["image_bytes"] = image_bytes

                st.image(image_bytes, caption="ì—…ë¡œë“œëœ ì†ê·¸ë¦¼", use_container_width=True)

                comps = detect_components(image_bytes)
                st.session_state["detected_components"] = comps

                with st.expander("ê°ì§€ëœ í™”ë©´ ì˜ì—­ (ì°¸ê³ ìš©)", expanded=False):
                    st.json([asdict(c) for c in comps])
            else:
                st.info("ì†ê·¸ë¦¼ì„ ì—…ë¡œë“œí•˜ì§€ ì•Šìœ¼ë©´, ê¸°ëŠ¥/í™”ë©´ ìš”ì†Œë§Œ ê¸°ì¤€ìœ¼ë¡œ ìš”êµ¬ì‚¬í•­ì„ ìƒì„±í•©ë‹ˆë‹¤.")

            if st.button("ë‹¤ìŒ ë‹¨ê³„ë¡œ"):
                st.session_state["current_step"] = 4
                st.rerun()
            if st.button("ì´ì „ ë‹¨ê³„ë¡œ"):
                st.session_state["current_step"] = 2
                st.rerun()

        elif current_step == 4:
            st.subheader("4ë‹¨ê³„: ìš”êµ¬ì‚¬í•­ & í™”ë©´ íë¦„ ìƒì„±")

            goal = st.session_state.get("goal", "").strip()
            selected_features = st.session_state.get("selected_features", [])
            selected_ui = st.session_state.get("selected_ui", [])
            detected_components = st.session_state.get("detected_components", [])
            has_img = st.session_state.get("image_bytes") is not None

            goal_topic = st.session_state.get("goal_topic", "ê¸°íƒ€(ë²”ìš©)")

            st.markdown("### ìš”ì•½")
            st.write(f"**ì•± ì£¼ì œ**: {goal if goal else 'ì…ë ¥ë˜ì§€ ì•ŠìŒ'}")
            st.write(f"**ë¶„ë¥˜ëœ ì£¼ì œ**: {goal_topic}")
            st.write(f"**ì„ íƒëœ ê¸°ëŠ¥**: {', '.join([f['name'] for f in selected_features]) if selected_features else 'ì—†ìŒ'}")
            st.write(f"**ì„ íƒëœ UI ì»´í¬ë„ŒíŠ¸**: {', '.join([ui['name'] for ui in selected_ui]) if selected_ui else 'ì—†ìŒ'}")
            st.write(f"**ì†ê·¸ë¦¼ ì—…ë¡œë“œ ì—¬ë¶€**: {'ì˜ˆ' if has_img else 'ì•„ë‹ˆì˜¤'}")

            if not goal:
                st.warning("ì•± ì£¼ì œê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. 1ë‹¨ê³„ë¡œ ëŒì•„ê°€ ì£¼ì œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
                if st.button("ì´ì „ ë‹¨ê³„ë¡œ"):
                    st.session_state["current_step"] = 3
                    st.rerun()
                return

            workflow = build_requirements_workflow()

            if st.button("ìš”êµ¬ì‚¬í•­ ë¬¸ì„œ ë§Œë“¤ê¸°", type="primary"):
                with st.spinner("LLMì´ ë‚´ìš©ì„ ì •ë¦¬í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        final_state = workflow.invoke(
                            {
                                "goal": goal,
                                "goal_topic": goal_topic,
                                "selected_features": selected_features,
                                "selected_ui": selected_ui,
                                "detected_components": detected_components,
                            }
                        )
                        payload = final_state["result_payload"]
                    except Exception as e:
                        st.error(f"ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                        return

                st.markdown("---")
                st.markdown("### ğŸ“„ ìš”êµ¬ì‚¬í•­ (Markdown)")
                req_md = payload.get("requirements_markdown", "").strip()
                if req_md:
                    st.markdown(req_md)
                else:
                    st.info("ìš”êµ¬ì‚¬í•­ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

                st.markdown("### ğŸ“ í™”ë©´ íë¦„ (ASCII ë‹¤ì´ì–´ê·¸ë¨)")
                ascii_diag = payload.get("ascii_diagram", "").strip()
                if ascii_diag:
                    st.code(ascii_diag, language="text")
                else:
                    st.info("ASCII ë‹¤ì´ì–´ê·¸ë¨ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

                with st.expander("LLM ì›ë³¸ JSON (ë””ë²„ê¹…ìš©)", expanded=False):
                    st.json(payload.get("debug_raw", {}))

                if payload.get("errors"):
                    st.warning("\n".join(payload["errors"]))

                with st.expander("ì—ì´ì „íŠ¸ ê³„íš & ê´€ì°° ë¡œê·¸", expanded=False):
                    st.markdown("**Plan Outline**")
                    st.json(payload.get("plan", {}))
                    st.markdown("**Observations**")
                    st.write(payload.get("observations", []))
                    st.markdown("**Actions Taken**")
                    st.write(payload.get("actions_taken", []))
                    st.markdown("**Tool Reports**")
                    st.json(payload.get("tool_reports", []))
                    st.markdown("**GPU Metrics**")
                    st.json(payload.get("gpu_metrics", []))
                    st.markdown("**Reasoning Trace**")
                    reasoning_trace = {
                        "sanitized_goal": payload.get("sanitized_goal"),
                        "reasoning_notes": payload.get("reasoning_notes"),
                        "info_requests": payload.get("info_requests"),
                    }
                    st.json(reasoning_trace)

            if st.button("ì´ì „ ë‹¨ê³„ë¡œ"):
                st.session_state["current_step"] = 3
                st.rerun()


if __name__ == "__main__":
    main()
